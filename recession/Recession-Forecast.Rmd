---
title: "Recession-Forecast"
author: "Jai Vrat Singh"
date: "23/09/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r warning=FALSE, message=FALSE}
rm(list=ls())
library(xts)
library(PerformanceAnalytics)
library(tseries)
library(forecast)
library(knitr)
library(kableExtra)
library(ggplot2)
library(glmnet)
library(caret)
library(visdat)
```

Set working directory

```{r}
setwd("/Users/jvsingh/work/github/R-codes/recession")

direct.df <- read.csv(file = "./data/2019-11.csv", header = TRUE, stringsAsFactors = FALSE, check.names = FALSE)
direct.df <- direct.df[-1, ] #The first row is transform etc..

#Date is in month/date/year format
direct.df$sasdate <- as.Date(direct.df$sasdate, "%m/%d/%Y")

#get into time series as it will be earier to work with
direct.df.xts <- xts(direct.df[,-1], direct.df$sasdate)


#Add another row of GS10-TB3MS
x.xts <-  direct.df.xts[, c("TB3MS", "GS10")]
bond.eqv <- function(discount)
{
  100 * (365 * discount/100)/(360 - 91 * discount/100)
}

x.xts$TB3MSBEQ       <- bond.eqv(as.numeric(x.xts$TB3MS))
x.xts$GS10_TB3MS     <- x.xts$GS10 - x.xts$TB3MSBEQ
old.names            <- names(direct.df.xts)
direct.df.xts        <- merge.xts(direct.df.xts, x.xts$GS10_TB3MS, all = TRUE, check.names = FALSE)
names(direct.df.xts) <- c(old.names, "GS10_TB3MS")

#Replace missing values by the latest observation. Please note that there may be missing values in "real" decision scenarios which may not be 
#caught by one time experiment. ie in case if we are doing real backtests
direct.df.xts <- zoo::na.locf(direct.df.xts)

#plot.xts(direct.df.xts[, c("TB3MS", "GS10", "GS10_TB3MS")], legend.loc = "topright")
```


```{r}
plot.xts(direct.df.xts, legend.loc = "bottomright")
```


As seen from the plot many series seem to be non-stationary. We need to check for seasonality and stationarity.

```{r}
#install.packages("visdat")
vis_dat(data.frame(direct.df.xts))
```

Seems that there are many missing till 1959-12-01. Let us drop these initial rows

```{r}
direct.df.xts <- window(direct.df.xts,start = as.Date("1959-12-01") + 1)
vis_dat(data.frame(direct.df.xts))
```



```{r}
#head(direct.df.xts[,1:10])
#For all columns let us create yoy, mom, qq, semi
#diff(direct.df.xts[, "RPI"], lag = 1, differences = 1, arithmetic = TRUE, log = FALSE, na.pad = TRUE, ...)

PCT <- FALSE

#------------------------ FUNCTION ---------------------------------#
#-- diff.periodic:   Calculate Periodic Differences
#-- input: col name, and pct/non.pct
#-------------------------------------------------------------------#
diff.periodic <- function(name, pct.diff){
                   this.xts  <- direct.df.xts[, name]
                   yoy <- diff(direct.df.xts[,name], lag = 12, 
                               differences = 1, 
                               arithmetic = TRUE, log = FALSE, na.pad = TRUE)
                   if(pct.diff)
                   {
                     yoy <- yoy/lag(direct.df.xts[,name], 12)
                   }
                   names(yoy) <- sprintf("%s_yoy", name)
                   
                   qoq <- diff(direct.df.xts[,name], lag = 3, 
                               differences = 1, 
                               arithmetic = TRUE, log = FALSE, na.pad = TRUE)
                   names(qoq) <- sprintf("%s_qoq", name)
                   if(pct.diff)
                   {
                     qoq <- qoq/lag(direct.df.xts[,name], 3)
                   }
                   
                   sem <- diff(direct.df.xts[,name], lag = 6, 
                               differences = 1, 
                               arithmetic = TRUE, log = FALSE, na.pad = TRUE)
                   if(pct.diff)
                   {
                     sem <- sem/lag(direct.df.xts[,name], 6)
                   }
                   names(sem) <- sprintf("%s_sem", name)
                   
                   
                   mom <- diff(direct.df.xts[,name], lag = 1, 
                               differences = 1, 
                               arithmetic = TRUE, log = FALSE, na.pad = TRUE)
                   if(pct.diff)
                   {
                     mom <- mom/lag(direct.df.xts[,name], 1)
                   }
                   names(mom) <- sprintf("%s_mom", name)
                   
                   list(yoy = yoy, sem=sem, qoq=qoq, mom=mom)
}



get.augmented.data <- function(direct.df.xts)
{
  res     <- sapply(names(direct.df.xts), function(name) diff.periodic(name = name, pct.diff = PCT), simplify = FALSE)

  res.xts <- NULL
  for(name in names(direct.df.xts))
  {
    # print(class(res[[name]]))
    if(is.null(res.xts))
    {
      res.xts <- direct.df.xts[ , name]
      names(res.xts) <- name
    } else {
      assign.names    <- c(names(res.xts), name)
      res.xts         <- merge.xts(res.xts, direct.df.xts[ , name])
      names(res.xts)  <- assign.names
    }
      this.xts        <- do.call(merge.xts, res[[name]])
      names(this.xts) <- as.character(unlist(lapply(res[[name]], names)))
      
      assign.names    <- c(names(res.xts), names(this.xts))
      res.xts         <- merge.xts(res.xts,this.xts)
      names(res.xts)  <- assign.names
  }
  res.xts
}

res.xts <- get.augmented.data(direct.df.xts)

```

##### Vizualize the enhanced dataset
```{r}
vis_dat(data.frame(coredata(res.xts)))
```

##### Unavailable data

Let us drop data which have more than 2% NA and also drop initial rows for which we hve implied NA's because of yoy/mom/sem transformations.
```{r}
x <- apply(res.xts, 2, function(x) sum(is.na(x))/length(x))
res.xts <- res.xts[, names(x[x<0.02])]
```


##### Check for seasonality
```{r}
is.any.seasonality <- sapply(names(res.xts), 
                             function(series.name){
                                res.tmp <- try(stl(res.xts[, series.name], s.window = "periodic"), silent = TRUE)
                                ifelse(class(res.tmp) == "try-error", FALSE, TRUE)
                             })
if(any(is.any.seasonality))
{
  warning("Some series are seasonal")
}
```

We find there is no seasonality issues in the transformed data


#### Check for Stationarity

Check for stationarity and drop those columns which as non-stationary

```{r}
#--------------------------------------------------------
#Function : p.values of adf.test. If pvalue <= 0.05 then stationary
#--------------------------------------------------------
testStationarity <- function(col.name, in.time.series.xts)
{
   this.ser <- in.time.series.xts[, col.name]
   adf.test(this.ser[!is.na(this.ser)])$p.value
}

suppressWarnings(test.pvals <- sapply(names(res.xts), function(col.name) testStationarity(col.name = col.name, in.time.series.xts = res.xts)))
# Non-stationary
#names(test.pvals)[test.pvals > 0.05]

#rop those columns which as non-stationary
res.xts <- res.xts[ ,names(test.pvals)[test.pvals <= 0.05] ]
```

#### Do we need to make them stationary (We have dropped non statinary above)
```{r}
# suggest.diff <- sapply(names(res.xts), 
#                              function(series.name){
#                                 forecast::ndiffs(res.xts[, series.name], alpha = 0.05, max.d = 10)
#                              })
# 
# suggest.diff.on.orig <- sapply(names(direct.df.xts), 
#                              function(series.name){
#                                 forecast::ndiffs(direct.df.xts[, series.name], alpha = 0.05, max.d = 10)
#                              })
# 
# stationarized <- sapply( direct.df.xts, function(in.xts){
#                                         #--function
#                                         this.lag <- suggest.diff.on.orig[as.character(names(in.xts))]
#                                         if(this.lag > 0)
#                                         {
#                                           return(diff.xts(in.xts, this.lag))
#                                         } else {
#                                           return(in.xts)
#                                         }
#                                         }, simplify = FALSE)
# for(i in 1:length(stationarized))
# {
#   res.xts <- merge.xts(res.xts, stationarized[[i]], check.names = FALSE)
# }
#Lets ignore it for a moment
```


#### Lets have look at NA's
```{r}
library(visdat)
vis_dat(data.frame(res.xts))
```



Because of yoy, many data till 1960-12-01 are NA. 

```{r}
res.xts   <- window(res.xts, start = as.Date("1960-12-01") + 1)
#Also Remove last rows which may be incomplete
res.xts   <- res.xts[complete.cases(res.xts), ]
```



```{r}
write.csv(res.xts, file = "/tmp/x.csv")

res.xts.df <- as.data.frame(res.xts, check.names = FALSE)


### pca of spliced
pca     <- prcomp(res.xts.df, scale = TRUE, center = TRUE)
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var) * 100, 1)
plot(pca.var.per, type = "l")

#pca$rotation

#PCA directions are pca$rotation[,1], pca$rotation[,2]
#apply(pca$rotation, 2, function(x) sum(x^2))

means.all <- apply(spliced.df, 2, mean)
sd.all    <- apply(spliced.df, 2, sd)

scaled.centered <-  (spliced.df[1, ] - means.all) / sd.all

#First is data mapped to principal component direction : scaled.centered %*% pca$rotation
#Second is pca$x
#as.matrix(scaled.centered) %*% pca$rotation - pca$x[1,]

#lest see of dropped columns are linear expressibly by rest of data, then we can simply drop them
sapply(names(dropped.df), function(col.name ){
  tmp <- data.frame("col" = dropped.df[[col.name]], as.data.frame(pca$x))
  tmp <- tmp[complete.cases(tmp), ]
  summary(lm( col ~ ., data = tmp))$adj.r.squared
})

#ABove Shows TWEXMMTH ANDENOx UMCSENTx may be dropped. But it might be better if we simply replace them by their median values. The algorithm can ignore them if sensitivity not found
tmp <- sapply(names(res.xts) , function(x){ 
                                           vals <- as.numeric(res.xts[, x])
                                           vals[is.na(vals)] <- median(vals, na.rm = TRUE)
                                           vals
                               })
tmp.xts <- xts(as.data.frame(tmp), index(res.xts))
names(tmp.xts) <- names(res.xts)

final.data.xts <- tmp.xts

setwd("~/work/github/R-codes/recession")

rec.df <- read.csv(file = "data/USREC.csv", stringsAsFactors = FALSE, header = TRUE)
rec.df$DATE = as.Date(rec.df$DATE)
rec.df.xts <- xts(rec.df$USREC, rec.df$DATE)
names(rec.df.xts) <- "USREC"

FORECAST.TENOR = 12
rec.df.adj.xts <- lag(rec.df.xts, -FORECAST.TENOR)
final.data.xts <- merge.xts(rec.df.adj.xts, final.data.xts)
final.data.xts <- final.data.xts[complete.cases(final.data.xts), ]

SPLIT  = 0.60
  
#70% train set
till.row  <- floor(SPLIT * dim(final.data.xts)[1])
train.idx <- (1:dim(final.data.xts)[1]) < till.row 

train_set <- final.data.xts[train.idx, ]
test_set  <- final.data.xts[!train.idx, ]

mu.s  <- apply(final.data.xts[train.idx, -1], 2, mean)
sig.s <- apply(final.data.xts[train.idx, -1], 2, sd)


```


```{r}

train_set.x.scaled <- scale(train_set[, -1], center = mu.s, scale = sig.s)
train_set.y.scaled <- train_set$USREC


mdlY = matrix(train_set$USREC, ncol = 1)
mdlX = train_set.x.scaled
set.seed(42)
cv_10 = trainControl(method = "cv", number = 10)
cv_5   = trainControl(method = "cv", number = 5)

dat.df <- data.frame("USREC" = as.factor(train_set$USREC), train_set.x.scaled)
mdlX = train_set.x.scaled


hit_elnet = train(
  USREC ~ ., data = dat.df,
  method = "glmnet",
  trControl = cv_5
)

hit_elnet$bestTune
hit_elnet$results

fit.glm <- glmnet(x = mdlX, y = as.matrix(train_set$USREC, ncol = 1), family = "binomial", alpha = hit_elnet$bestTune["alpha"], 
       lambda =  hit_elnet$bestTune["lambda"],
       intercept=TRUE, standardize = FALSE)
summary(fit.glm)
fit.glm$beta
fit.glm$a0
plot(fit.glm)
coef(fit.glm)

```

```{r}
#ON Train Set 
pred.prob.train <- predict(fit.glm, as.matrix(train_set.x.scaled), type = "response")

resp.train.xts <- xts(pred.prob.train, index(train_set))
resp.train.xts <- merge.xts(resp.train.xts, train_set$USREC)
plot(resp.train.xts)
```

```{r}
#Prediction on Test Set
test_set.x.scaled <- scale(test_set[, -1], center = mu.s, scale = sig.s)
pred.prob <- predict(fit.glm, as.matrix(test_set.x.scaled), type = "response")

resp.test.xts <- xts(pred.prob, index(test_set.x.scaled))
resp.test.xts <- merge.xts(resp.test.xts, test_set$USREC)

plot(resp.test.xts)


#
# Roc curve
library(ROCR)
pred <- prediction(predictions = pred.prob, labels = test_set$USREC) 
perf <- performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)


#AUC
performance(pred,measure = "auc")@y.values[[1]]

```




