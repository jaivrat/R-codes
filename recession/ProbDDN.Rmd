---
title: "ProbDDN"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r warning=FALSE, message=FALSE}
rm(list=ls())
library(xts)
library(PerformanceAnalytics)
library(tseries)
library(forecast)
library(knitr)
library(kableExtra)
library(ggplot2)
library(glmnet)
library(caret)
#install.packages("visdat")
library(visdat)
library(lubridate)
library(ggplot2)
```



Set working directory

```{r}
setwd("/Users/jvsingh/work/github/R-codes/recession")

direct.df <- read.csv(file = "./data/2019-11.csv", header = TRUE, stringsAsFactors = FALSE, check.names = FALSE)
direct.df <- direct.df[-1, ] #The first row is transform etc..

#Date is in month/date/year format
direct.df$sasdate <- as.Date(direct.df$sasdate, "%m/%d/%Y")

#get into time series as it will be earier to work with
direct.df.xts <- xts(direct.df[,-1], direct.df$sasdate)

#Replace missing values by the latest observation. Please note that there may be missing values in "real" decision scenarios which may not be 
#caught by one time experiment. ie in case if we are doing real backtests
direct.df.xts <- zoo::na.locf(direct.df.xts)

rec.df            <- read.csv(file = "data/USREC.csv", stringsAsFactors = FALSE, header = TRUE)
rec.df$DATE       <- as.Date(rec.df$DATE)
rec.df.xts        <- xts(rec.df$USREC, rec.df$DATE)
names(rec.df.xts) <- "USREC"



#Add another row of GS10-TB3MS
x.xts <-  direct.df.xts[, c("TB3MS", "GS10")]
bond.eqv <- function(discount)
{
  100 * (365 * discount/100)/(360 - 91 * discount/100)
}

x.xts$TB3MSBEQ       <- bond.eqv(as.numeric(x.xts$TB3MS))
x.xts$GS10_TB3MS     <- x.xts$GS10 - x.xts$TB3MSBEQ
old.names            <- names(direct.df.xts)
direct.df.xts        <- merge.xts(direct.df.xts, x.xts$GS10_TB3MS, all = TRUE, check.names = FALSE)
names(direct.df.xts) <- c(old.names, "GS10_TB3MS")

#Let us restrict to two columns only for HMM: S&P 500 and GS10_TB3MS
dat.xts <- merge.xts(CalculateReturns(direct.df.xts$`S&P 500`, method = "log"), direct.df.xts$GS10_TB3MS)
dat.xts <- dat.xts[complete.cases(dat.xts), ]
names(dat.xts) <- c("sp500ret", "g10_3")
```


Model Building
```{r}

observed <- matrix(coredata(dat.xts), byrow = FALSE, ncol = 2)

library(depmixS4)
#Model with 3 states
rModels <- list()

num.states <- 5
for(i in 1:num.states)
{
  rModels[[i]] <- list(depmixS4::MVNresponse(observed ~ 1))
}

set.seed(42)
transition.mat <- list()
for(i in 1:num.states)
{
  tmp <- rep(NA, num.states)
  #Self probabailty to be high obviously
  tmp[i] <- runif(1, min = 0.5, max = 1)
  rands <- runif(num.states - 1)
  tmp[-i] <- ( 1 - tmp[i]) * rands/sum(rands) #distrbute to remaining
  transition.mat[[i]] = transInit(~1, nstates = num.states, data = data.frame(1), pstart = tmp)
}

p.init.states <- runif(num.states)
#p.init.states <- p.init.states/sum(p.init.states)

inMod <- transInit(~1, ns = num.states, ps = p.init.states, data = data.frame(1))

model <- depmixS4::makeDepmix(response = rModels, transition = transition.mat, prior = inMod)

set.seed(42)
fit.model <- fit(model, emc = em.control(random.start = FALSE))

```


```{r}
#fit.model@posterior
dim(fit.model@posterior)
dim(observed)

#Logistic to see which is recession state
tmp.xts <- xts(as.data.frame(fit.model@posterior[,-1]), index(dat.xts))
plot(tmp.xts, legend.loc = "topleft")

tmp.xts <- merge.xts(tmp.xts, rec.df.xts, all = FALSE)
tmp.xts.df <- as.data.frame(tmp.xts)
tmp.xts.df$USREC <- as.factor(tmp.xts.df$USREC)
log.fit <- glm( USREC ~ ., data = tmp.xts.df, family = "binomial" )
summary(log.fit)

plot.xts(tmp.xts[, c("S2", "USREC")], legend.loc = "topright")

#fit.model@posterior
#fit.model@trDens
#fit.model@init
 
```



```{r}
## Description of states: two variables so two simensional

describeStates <- function(in.fit.model)
{
  description <- list()
  for(i in 1:in.fit.model@nstates)
  {
    mu <- as.numeric(in.fit.model@response[[i]][[1]]@parameters$coefficients)
    Sigma <- in.fit.model@response[[i]][[1]]@parameters$Sigma
    Sigma.mat <- rbind(c(Sigma[1], Sigma[2]),
                       c(Sigma[2], Sigma[3]))
    description[[i]] <- list(mu = mu, Sigma.mat = Sigma.mat)
  }
  description
}


max.ddn.measures <- function(in.fit.model)
{
  description <- describeStates(in.fit.model)
  result      <- rep(0, in.fit.model@nstates)
  for(i in 1:in.fit.model@nstates)
  {
    result[i] <- fBasics::maxddStats(mean = description[[i]]$mu[1], 
                                     sd = sqrt(description[[i]]$Sigma.mat[1,1]), 
                                     horizon =12)
  }
  result
}

max.ddn.measures(in.fit.model = fit.model)
```



```{r}

#simulateData <- function(fit.model, n, start.state)
simulateData <- function(in.init.state.probs, in.trans.prob, in.description, in.num.states, n.periods, in.start.state)
{
  #init.state.probs <- fit.model@init
  #trans.prob <- matrix(as.numeric(fit.model@trDens), nrow = num.states, ncol =num.states, byrow = TRUE)
  
  #list of mu and sigma
  #description <- describeStates(fit.model)
  
  realised.states <- rep(NA, n.periods)
  curr.state = in.start.state
  for(i in 1:n.periods)
  {
    prob.of.next.states = as.numeric(in.trans.prob[curr.state, ])
    #if too small, limit to 10-3
    prob.of.next.states[prob.of.next.states<1e-3] = 1e-3
    prob.of.next.states  = prob.of.next.states/sum(prob.of.next.states)
    realised.states[i] <- sample(1:in.num.states, size = 1, prob = prob.of.next.states)
    curr.state = realised.states[i]
    #print(sprintf("currstate = %s", curr.state))
  }
  
  emissions <- sapply(1:n.periods, function(i) {
    state <- realised.states[i]
    rnd <- mvrnorm(n = 1, mu = in.description[[state]]$mu, Sigma = in.description[[state]]$Sigma.mat)
    rnd[1] #first is log returns of S&P
  })
  
  emissions
}

getStartState <- function(in.fit.model)
{
  last(in.fit.model@posterior)$state
}

start.state <- getStartState(fit.model)
n.periods   <- 12
nextDates   <- as.Date(sapply( 1:n.periods, function(i) as.character(last(index(dat.xts)) %m+% months(i))))

getSamplePath <- function(in.init.state.probs, in.description, in.num.states, in.trans.prob, in.start.state)
{
  tmp.sim.logret <- simulateData(in.init.state.probs = in.init.state.probs,
                                 in.description = in.description, 
                                 in.num.states = in.num.states, 
                                 in.trans.prob = in.trans.prob,
                                 n.periods = n.periods, 
                                 in.start.state = in.start.state)
  tmp.sim.logret
  #tmp.ret.xts    <- xts(tmp.sim.logret, nextDates)
  #tmp.ret.xts
}

```



```{r}
SIM = 1000
PARALLEL = FALSE

trans.prob <- matrix(as.numeric(fit.model@trDens), nrow = num.states, ncol =num.states, byrow = TRUE)
init.state.probs = fit.model@init
description  <- describeStates(fit.model)

ddns <- NULL
if(PARALLEL)
{
  library(parallel)

  cl <- parallel::makeCluster(parallel::detectCores() - 1)
  
  clusterExport(cl, c( "getSamplePath", "simulateData", "fit.model", "num.states","n.periods",
                      "describeStates", "start.state", "mvrnorm", "nextDates", "trans.prob", "description"))
  
  ddns <- parSapply(cl, 1:SIM,  function(i) {
                            library(xts)
                            sim.logret <- getSamplePath(
                                                in.init.state.probs = init.state.probs,
                                                in.description = description, 
                                                in.num.states = num.states,
                                                in.trans.prob =trans.prob, 
                                                in.start.state = start.state)
                            tmp.ret.xts <- xts(sim.logret,nextDates)
                            PerformanceAnalytics::maxDrawdown(tmp.ret.xts)
    })
  
  stopCluster(cl)
} else {
  ddns <- sapply(1:SIM,  
                 function(i) 
                 {
                   sim.logret <- getSamplePath(
                                                in.init.state.probs = init.state.probs,
                                                in.description = description, 
                                                in.num.states = num.states,
                                                in.trans.prob =trans.prob, 
                                                in.start.state = start.state)
                   tmp.ret.xts <- xts(sim.logret,nextDates)
                   PerformanceAnalytics::maxDrawdown(tmp.ret.xts)
                 })
}
```




```{r}
library(scales)
pcts <- seq(from = 0, to = 1, by = 0.05) 
probs <- sapply(pcts, function(pct) mean(ddns>pct))
ddn.df <- data.frame(drawdowns = pcts, "probability" = probs)
ggplot(data = ddn.df, aes(x = drawdowns, y = probability)) + geom_line() + geom_point() +
  scale_y_continuous(labels = percent) + 
    scale_x_continuous(labels = percent)
```

```{r}
ggplot(data.frame(ddns = ddns), aes(x=ddns)) +
  geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   #binwidth=.5,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666") + # Overlay with transparent density plot
scale_x_continuous(labels = percent)
```

```{r}
pcts <- seq(from = 0, to = 1, by = 0.10) 
ddn.res <- data.frame(drawdown.pct = seq(from = 0, to = 1, by = 0.10) * 100 ,
                     "probability >drawdown.pct" = sapply(pcts, function(pct) mean(ddns>pct)) * 100, check.names = FALSE)
ddn.res
```



##### Validation of drawdowns

```{r}

#----------------------------- Functions
getFittedModel <- function(in.dat.xts, in.num.states)
{
    observed <- matrix(coredata(in.dat.xts), byrow = FALSE, ncol = 2)
    library(depmixS4)
    #Model with 3 states
    rModels <- list()
    for(i in 1:in.num.states)
    {
       rModels[[i]] <- list(depmixS4::MVNresponse(observed ~ 1))
    }
  
    #set.seed(42)
    transition.mat <- list()
    for(i in 1:in.num.states)
    {
      tmp <- rep(NA, in.num.states)
      #Self probabailty to be high obviously
      tmp[i] <- runif(1, min = 0.5, max = 1)
      rands <- runif(in.num.states - 1)
      tmp[-i] <- ( 1 - tmp[i]) * rands/sum(rands) #distrbute to remaining
      transition.mat[[i]] = transInit(~1, nstates = in.num.states, data = data.frame(1), pstart = tmp)
    }
  
    p.init.states <- runif(in.num.states)
    p.init.states <- p.init.states/sum(p.init.states)
    
    inMod <- transInit(~1, ns = in.num.states, ps = p.init.states, data = data.frame(1))
  
    model <- depmixS4::makeDepmix(response = rModels, transition = transition.mat, prior = inMod)
  
    set.seed(42)
    fit.model <- fit(model, emc = em.control(random.start = FALSE))
    fit.model
}

#1. Fix a current date for future prediction

#2. Fit a model for data till this date

#2. Determine Latest state and model paramaters.

#3. Simulate N Observations

#4. Determine Expected Returns, the std deviation boundsof this Expected Returns

#5. Get the Actual 12 drawdowns


#6 Plot

getOutcome.For.Date <- function(now.Date)
{
  #1. Fix a current date for future prediction
  train.data <- window( dat.xts, end = now.Date)

  #2. Fit a model for data till this date
  fitted.model <- getFittedModel(in.dat.xts = train.data, in.num.states = num.states)

  #2. Determine Latest state and model paramaters.
  latest.state <- last(fitted.model@posterior)$state
  #Model Paramteres
  init.state.probs <- fitted.model@init
  trans.prob <- matrix(as.numeric(fitted.model@trDens), nrow = num.states, ncol = num.states, byrow = TRUE)
  #list of mu and sigma
  description <- describeStates(fitted.model)

  #3. Simulate N Observations
  nextDates   <- as.Date(sapply( 1:n.periods, function(i) as.character(last(index(dat.xts)) %m+% months(i))))

  #imulate N sample paths
  sim.paths.xts <- xts(sapply(1:SIM, function(i){
                       sim.logret <- getSamplePath(
                                        in.init.state.probs = init.state.probs,
                                        in.description = description, 
                                        in.num.states = num.states,
                                        in.trans.prob = trans.prob, 
                                        in.start.state = start.state)
                        sim.logret
                    }),
                 nextDates)
  sim.ddns <- as.numeric(PerformanceAnalytics::maxDrawdown(sim.paths.xts))
  expected <- mean(sim.ddns)
  std.dev  <-  sd(sim.ddns)
  rest     <- sapply(1:20, function(i) mean(sim.ddns > 0.05 * i) ) #Prob( ddn > x%)
  c(expected -  std.dev, expected, expected +  std.dev,rest)
}

now.Date   <- as.Date("1999-12-31")
getOutcome.For.Date(now.Date)


```

```{r}
SIM = 100000
start.date = as.Date("1990-12-31")
run.for.dates <- index(dat.xts)[index(dat.xts) > start.date]

ddns.stats <- NULL

library(parallel)

cl <- parallel::makeCluster(parallel::detectCores() - 1)
  
clusterExport(cl, c( "getSamplePath", "simulateData", "fit.model", "num.states","n.periods",
                      "describeStates", "start.state", "mvrnorm", "nextDates", "trans.prob", "description", 
                     "getOutcome.For.Date", "dat.xts", "getFittedModel", "SIM"))
  
ddns.stats <- parSapply(cl, run.for.dates,  function(now.Date) {
                                              now.Date <- as.Date(now.Date)
                                              library(xts)
                                              library(lubridate)
                                              set.seed(42)
                                              getOutcome.For.Date(now.Date)})
  
stopCluster(cl)
ddns.stats.xts <- xts(t(ddns.stats), run.for.dates)
out.file.ddns.stats.xts  <- sprintf("/Users/jvsingh/work/github/R-codes/recession/data/ddns.stats.xts.%s.rds", SIM)
#saveRDS(ddns.stats.xts, out.file.ddns.stats.xts)
```



#### Analysis on above saved data

```{r}
#Let us plot exact observed drawdowns in next 12 months

obs.ret.xts <- xts(sapply(run.for.dates, function(now.Date){
                      now.Date = as.Date(now.Date)
                      fut.date  = now.Date %m+% months(n.periods)
                      chunk.xts = window(dat.xts$sp500ret, start = now.Date, end = fut.date)
                      PerformanceAnalytics::maxDrawdown(chunk.xts)
                    }), run.for.dates)

results.xts <- merge.xts(ddns.stats.xts[, 1:3], obs.ret.xts, all = FALSE)
names(results.xts) <- c("lb", "expected", "ub", "observed")

plot.xts(results.xts, legend.loc = "topright")
```